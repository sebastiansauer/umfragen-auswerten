[{"path":"index.html","id":"einleitung","chapter":"Kapitel 1 Einleitung","heading":"Kapitel 1 Einleitung","text":"Fragebogendaten zu psychologischen Variablen (wie z.B. Extraversion), die wissenschaftlichen Ansprüchen genügen, bezeichnet man als psychometrische Daten (vgl. Steyer Eid 1993).\nDer Analyse psychometrischer Daten kommt große Bedeutung innerhalb der Psychologie (und angrenzender Gebiete wie Marketing) zu.\nDer Grund ist, dass Daten häufig Form von Fragebogen, psychometrischer Fragebogen, erhoben werden.\nBesonders für Persönlichkeitskonstrukte und Einstellungen, kurz für Fragestellungen der Persönlichkeitspsychologie und, davon abgeleitet, der Diagnostik,\nerfreuen sie sich weiter Verbreitung.Ziel dieses Beitrags ist es, eine praktische Anleitung für typische (und grundlegende) psychometrischen Analysen mittels R zu geben.\nDabei soll demonstriert und erläutert werden, welche Analysen und wie durchgeführt werden\neiner grundständigen psychometrischen Analyse.\nEs wird sowohl der Einzelfall-Diagnostik Rechnung getragen, als auch der Testvalidierung.\nAnders gesagt, dieses Dokument hilft, u.. folgende Fragen zu beantworten:\n“Wie leistungsfähig war der Applikant im Vergleich zu seiner Referenzgruppe?”,\n“Wie ist die Qualität dieses Testverfahrens einzuschätzen?”.Test wird hier verstanden sensu (Lienert1998?) (S. 14f):ein wissenschaftliches Routineverfahren zur Untersuchung eines oder mehrerer empirisch abgrenzbarer Persönlichkeitsmerkmale mit dem Ziel einer möglichst quantitativen Aussage über den relativen Grad der individuellen Merkmalsausprägung.Inhalte werden im Rahmen einer Fallstudie erarbeitet;\nd.h. es wird ein echter Datensatz analysiert, wobei einige Hintergründe zu den verwendeten Methoden erläutert werden.","code":""},{"path":"index.html","id":"hilfe-zu-r","chapter":"Kapitel 1 Einleitung","heading":"1.1 Hilfe zu R","text":"Eine praktische Einführung zu Datenanalyse bietet ModernDive (auf Englisch); eine umfassende Einführung Englisch findet sich bei Sauer (2019).","code":""},{"path":"index.html","id":"zu-messendes-konstrukt-extraversion","chapter":"Kapitel 1 Einleitung","heading":"1.2 Zu messendes Konstrukt: Extraversion","text":"Satow (2012) definiert Extraversion wie folgt:Extraversion (E) (Gegenteil: Introversion): Bereits C.G. Jung (1921) hatte beobachtet, dass Menschen entweder eher nach außen (gesellig, gesprächig, abenteuerlustig) oder nach innen orientiert (nachdenklich, -sich-gekehrt) sind. Aufgrund dieser Beobachtungen hielt Eysenck (1947) Extraversion für einen der drei wesentlichen Persönlichkeitsdimensionen. Spätere Untersuchungen konnten zeigen, dass erfolgreiche Führungskräfte häufig eher extravertiert sind und dass Arbeitsleistung und Arbeitszufriedenheit generell mit Extraversion korrelieren (Judge et al., 2002; Lim & Ployhart, 2004) – wobei es jedoch auch Ausnahmen gibt. sind überraschend viele erfolgreiche Unternehmensgründer und besonders innovative Persönlichkeiten wie Bill Gates, Warren Buffett oder Steven Spielberg häufig überraschend introvertiert (Jones, 2006).","code":""},{"path":"index.html","id":"messinstrument","chapter":"Kapitel 1 Einleitung","heading":"1.3 Messinstrument","text":"Es wird ein Datensatz zur Extraversion analysiert.\nExtraversion wurde operationalisiert mit dem Inventar B5T von Satow (Satow 2020).\nDas Instrument besteht aus 10 Items mit vier Likert-Antwortstufen (von “trifft gar nicht zu” bis “trifft voll und ganz zu”) und ist für Forschungszwecke kostenlos nutzbar1:der B5T ist als Paper-Pencil-Version, Excel-Version sowie als Online-Version verfügbar und kann für nichtkommerzielle Forschungs- und für Unterrichtszwecke kostenlos verwendet werden. Der B5T wurde offiziell die PSYNDEX-Testdatenbank (Tests-Nr. 9006357) und das elektronische Testarchiv des Leibniz-Zentrums für Psychologische Information und Dokumentation (ZPID) aufgenommen.anderer Stelle2 ist zur Lizenz zu lesen:Lizenz: Sie dürfen den Test ausschließlich zu Forschungs- und Unterrichtszwecken einsetzen und übersetzen. Sie müssen die Quelle nennen und ein elektronisches Belegexemplar oder die Quellenangabe (Autor, Titel, Zeitschrift/Buch, Erscheinungsjahr) Ihrer Veröffentlichung mailATdrsatow.de senden.Zur Reliabilität berichtet Satow (2012), dass Cronbachs Alpha bei .87 läge, ein guter Wert ist. Machen wir diese Variable für R verfügbar:Der Test hat einige Validierungsstudien erfahren, allerdings ist die Qualität dieser Studien zum Teil fraglich, da es sich um “graue” Literatur handelt, also Literatur, die nicht öffentlich (einfach) zugänglich ist. Außerdem gibt es kaum Fachartikel, die ein Blind-Begutachtungsverfahren durchlaufen hätten; die meisten Studien zum B5T basieren auf Abschlussarbeiten; auch einige von FOM-Studierenden sind zu finden.Die Items zum Test sind über die Webseite des Anbieters abrufbar3.","code":"\nextra_alpha <- .87"},{"path":"index.html","id":"r-pakete","chapter":"Kapitel 1 Einleitung","heading":"1.4 R-Pakete","text":"Folgende R-Pakete werden für diesen Kurs benötigt.\nBitte stellen Sie sicher, dass Sie diese Pakete vor Beginn der Analyse installiert haben.\nSie installieren ein R-Paket mit dem Befehl install.packages(name_des_pakets).","code":"\nlibrary(mosaic)  # Statistik allgemein\nlibrary(tidyverse)  # Datenjudo\nlibrary(sjmisc)  # Deskriptive Statistik\n# library(apa)  # Statistiken nach APA formatieren\nlibrary(mice)  # Hilfen für fehlende Werte\nlibrary(devtools)  # Pakete von Github installieren\nlibrary(ggstatsplot)  # Visualisierung\nlibrary(janitor)  # Daten aufräumen\nlibrary(ggpubr)  # Visualisierung\nlibrary(psych)  # psychometrische Analyse"},{"path":"index.html","id":"vertiefung-infos-zu-paketen","chapter":"Kapitel 1 Einleitung","heading":"1.5 Vertiefung: Infos zu Paketen","text":"Sie fragen sich, das Paket praise(), fortunues() oder R_for_superheros()4 für Sie bereithält? Mit folgender Funktion bekommen Sie die Hilfe-Seiten eines Pakets angezeigt.","code":"\nhelp(package = \"apa\") "},{"path":"index.html","id":"daten","chapter":"Kapitel 1 Einleitung","heading":"1.6 Daten","text":"","code":""},{"path":"index.html","id":"daten---aus-paket-pradadata","chapter":"Kapitel 1 Einleitung","heading":"1.6.1 Daten - aus Paket pradadata","text":"Die Daten können über mehrere Weg abgerufen werden. Eine Möglichkeit bietet das R-Paket pradadata5, da es auf Github6 zu finden ist, muss zuerst ein Paket verfügbar sein, dass R-Paket von dort aus installiert. Dazu verwenden wir das Paket devtools; wie jedes Paket muss es zuerst installiert sein:Dann können wir das Paket installieren:laden und daraus den Datensatz zur Extraversion:Betrachten wir den Datensatz","code":"\ninstall.packages(\"devtools\")  # nur einmalig\ninstall_github(\"sebastiansauer/pradadata\")\nlibrary(\"pradadata\")\ndata(extra)\ninspect(extra)"},{"path":"index.html","id":"daten---via-webseite","chapter":"Kapitel 1 Einleitung","heading":"1.6.2 Daten - via Webseite","text":"Alternativ zur Installation via R-Paket pradadata stehen die Daten unter diesem Link zum Herunterladen bereit:","code":"\ndata_url <- \"https://raw.githubusercontent.com/sebastiansauer/modar/master/datasets/extra.csv\"\nextra <- read_csv(data_url)"},{"path":"index.html","id":"umfrage-zu-den-daten","chapter":"Kapitel 1 Einleitung","heading":"1.6.3 Umfrage zu den Daten","text":"Die Daten wurden mit dieser Umfrage erhoben.","code":""},{"path":"index.html","id":"technische-hinweise","chapter":"Kapitel 1 Einleitung","heading":"1.7 Technische Hinweise","text":"Sessioninfo:Datum: 2022-05-02R-Version: R version 4.1.3 (2022-03-10)Betriebssystem:","code":""},{"path":"daten-aufräumen.html","id":"daten-aufräumen","chapter":"Kapitel 2 Daten aufräumen","heading":"Kapitel 2 Daten aufräumen","text":"","code":""},{"path":"daten-aufräumen.html","id":"r-pakete-1","chapter":"Kapitel 2 Daten aufräumen","heading":"2.1 R-Pakete","text":"diesem Kapitel benötigen wir folgende R-Pakete:","code":"\nlibrary(tidyverse)  # Datenjudo\nlibrary(sjmisc)  # recode\nlibrary(ggstatsplot)  # Diagram aufbügeln\nlibrary(mice)  # Fehlende Werte ersetzen"},{"path":"daten-aufräumen.html","id":"daten-1","chapter":"Kapitel 2 Daten aufräumen","heading":"2.2 Daten","text":"","code":"\ndata_url <- \"https://raw.githubusercontent.com/sebastiansauer/modar/master/datasets/extra.csv\"\nextra <- read_csv(data_url)"},{"path":"daten-aufräumen.html","id":"überblick","chapter":"Kapitel 2 Daten aufräumen","heading":"2.3 Überblick","text":"Häufig sind Daten noch nicht “aufbereitet” und müssen noch “geputzt” oder “aufgeräumt” werden. Dazu gehören Schritte wieDaten umkodierenDaten aggregierenDaten gruppierenFehlende Werte ersetzenDatenqualität prüfenVerteilungsformen prüfenAusreißer behandelnBetrachten wir einige zentrale Aspekte dieser Schritte.","code":""},{"path":"daten-aufräumen.html","id":"brave-daten","chapter":"Kapitel 2 Daten aufräumen","heading":"2.4 Brave Daten","text":"Wie muss eine Tabelle gestaltet sein,\ndamit man sie gut R importieren kann, bzw. gut damit weiterarbeiten kann?Das ist eine gute Quelle zu diesem Thema.Im Überblick sollten Sie auf Folgendes achten:Wenn Sie händisch Daten eintragen, hacken Sie das einfach Excel sein.CSV-Dateien bieten sich als Datenformat .Alternativ kann man auch Excel-Dateien R importieren.Es muss genau eine Kopfzeile geben.Es darf keine Lücken geben (leere Zeilen oder Spalten oder Zellen).Vermeiden Sie Umlaute und Leerzeichen den Variablennamen.Beachten Sie das Prinzip von “tidy data”:jeder Zeile steht eine Beobachtung.jeder Spalte steht eine Variable.jeder Zelle steht eine Wert.","code":""},{"path":"daten-aufräumen.html","id":"text-in-zahlen-umwandeln","chapter":"Kapitel 2 Daten aufräumen","heading":"2.5 Text in Zahlen umwandeln","text":"","code":""},{"path":"daten-aufräumen.html","id":"hilfe-ich-habe-keine-zahlen","chapter":"Kapitel 2 Daten aufräumen","heading":"2.5.1 Hilfe, ich habe keine Zahlen","text":"Kennen Sie das? Sie haben eine Umfrage durchgeführt, Daten sind erhoben, puh, bald können Sie das Projekt abschließen.Jetzt haben Sie die Daten R importiert,\naber müssen zu Ihrem Schrecken feststellen,\ndass die Spalten (Variablen) die eigentlich Zahlen sein sollten,\nals character, Text also, formatiert sind R.Anstelle der Zahl 5 steht der Spalte also \"5\" (man beachte die Anführungszeichen, die anzeigen, dass es sich um einen Text handelt).Na toll.Mit Wörtern (Text) kann man nicht rechnen, und Sie rechnen doch gern…R weigert sich standhaft, mit Text zu rechnen:Hätten wir brave Zahlen, wäre alles paletti:Der Einfachheit halber erzeugen wir uns eine einfache Tabelle, mit ein paar Spalten,\ndie als Text formatierte Zahlen enthalten:Für diejenigen, die kompliziert mögen, ist hier noch eine factor-Spalte hinzugefügt. Erstmal ignorieren.Stellen Sie sich vor, die Tabelle ist ein Auszug aus Ihrer Umfrage,\nwobei i01 das erste Item (Frage) Ihres Fragebogens darstellt etc.Wie kann man R beibringen,\ndass die fraglichen Spalte i01 doch “Wirklichkeit” Zahlen sind und kein Text?Welcher R-Befehl hilft hier?","code":"\n\"5\" + \"5\"\n#> Error in \"5\" + \"5\": non-numeric argument to binary operator\n5+5\n#> [1] 10\nlibrary(tidyverse)\n\nd <- tibble(i01 = c(\"1\", \"3\", \"4\"),  # von 1 bis 4\n            i02 = c(\"-2\", \"+3\", \"-1\"),  # von -3 bis -3\n            i03 = factor(c(\"-2\", \"+2\", \"-1\")))  # als Faktorvariable formatiert\nd\n#> # A tibble: 3 × 3\n#>   i01   i02   i03  \n#>   <chr> <chr> <fct>\n#> 1 1     -2    -2   \n#> 2 3     +3    +2   \n#> 3 4     -1    -1"},{"path":"daten-aufräumen.html","id":"introducing-parse_number","chapter":"Kapitel 2 Daten aufräumen","heading":"2.5.2 Introducing parse_number()","text":"parse_number() (aus tidyverse) löst das Problem für Sie:würde es einigen Fällen auch gehen:Aber wenn i01 als factor() formatiert ist, dann geht es nicht unbedingt.Hoppla! Die Zahlen passen nicht!parse_number() verlangt als Input character,\ndass Sie ggf. noch von factor auf character umformatieren müssen.","code":"\nd2 <- \n  d %>% \n  mutate(i01 = parse_number(i01))\nd\n#> # A tibble: 3 × 3\n#>   i01   i02   i03  \n#>   <chr> <chr> <fct>\n#> 1 1     -2    -2   \n#> 2 3     +3    +2   \n#> 3 4     -1    -1\nd %>% mutate(i01_r = as.numeric(i01))\n#> # A tibble: 3 × 4\n#>   i01   i02   i03   i01_r\n#>   <chr> <chr> <fct> <dbl>\n#> 1 1     -2    -2        1\n#> 2 3     +3    +2        3\n#> 3 4     -1    -1        4\nd %>% mutate(i02_r = as.numeric(factor(i02)))\n#> # A tibble: 3 × 4\n#>   i01   i02   i03   i02_r\n#>   <chr> <chr> <fct> <dbl>\n#> 1 1     -2    -2        2\n#> 2 3     +3    +2        3\n#> 3 4     -1    -1        1\nd %>% mutate(i03_r = parse_number(as.character(i03)))\n#> # A tibble: 3 × 4\n#>   i01   i02   i03   i03_r\n#>   <chr> <chr> <fct> <dbl>\n#> 1 1     -2    -2       -2\n#> 2 3     +3    +2        2\n#> 3 4     -1    -1       -1"},{"path":"daten-aufräumen.html","id":"daten-umformen","chapter":"Kapitel 2 Daten aufräumen","heading":"2.6 Daten umformen","text":"einer Fragebogenstudie (oder vergleichbarer Studie) liegen der Regel pro Respondent (allgemeiner: pro Beobachtung) eine Reihe von Antworten auf Fragebogen-Items vor.\nManchmal liegen die Antworten noch nicht als Zahl vor, sondern als Text, etwa “stimme eher zu”.\nDiese Antwort könnte auf einer vierstufigen Skala einer 3 entsprechen. Eine einfache Möglichkeit zum Umkodieren eröffnet das Paket sjmisc.\nAls Beispielaufgabe soll der Wert “Frau” 1 umkodiert werden und “Mann” 0; übrige Werte sollen NA kodiert werden.Dabei wird eine neue Variable (Spalte) erzeugt, deren Namen der alten Variable entspricht, plus dem Suffix _r, diesem Fall also sex_r. Man beachte, dass Textwerte (Strings) nicht Anführungsstriche gesetzt werden müssen, nur der ganze “Rekodierungsterm” muss einmal Anführungsstriche gesetzt werden.Prüfen wir das Ergebnis:","code":"\ndata_rec <- extra %>% \n  rec(sex, rec = \"Frau = 1; Mann = 0; else = NA\")\ndata_rec %>% \n  count(sex_r)\n#> # A tibble: 3 × 2\n#>   sex_r     n\n#>   <chr> <int>\n#> 1 0       286\n#> 2 1       529\n#> 3 <NA>     11"},{"path":"daten-aufräumen.html","id":"items-umkodieren","chapter":"Kapitel 2 Daten aufräumen","heading":"2.7 Items umkodieren","text":"Fragebogen werden immer wieder Items negativ kodiert. Das bedeutet, dass sie gegenteilig zum messenden Konstrukt formuliert sind. Ist das Konstrukt Extraversion, würde ein negatives Item im Sinne von Introversion kodiert sein. Ein Beispiel-Item für negative Kodierung wäre: “Ich bin ein Couch-Potato” oder “Ich bleibe liebsten alleine zuhause.”Zuerst müssen wir die Anzahl der Antwortstufen wissen; diese Information findet sich der Dokumentation der Skala (im “Manual” auch “Testdokumentation” oder “Benutzerhandbuch” genannt). Natürlich kann man prüfen, welche Antwortstufen die Respondenten gefunden haben, aber man wäre nicht sicher, ob auch alle möglichen Antworten ausgeschöpft wurden.Im vorliegenden Fall ist der Dokumentation des Instruments zu entnehmen, dass jedes Item vier Antwortstufen (Likertformat) aufweist. Likert-skalierte Items zeichnen sich dadurch aus, dass sie formuliert sind, dass höhere Werte der Antwortstufe mit höherer Ausprägung des zu messenden Konstrukts einher gehen.Beim Umkodieren wird das Item “auf den Kopf gestellt”: Der höchste Wert wird der kleinste, der zwei kleinste wird der zweitgrößte und weiter. Im Schema sieht dies aus:Zum Umkodieren negativ kodierter Items bietet sich wieder die Funktion rec aus sjmisc.diesem Fall ist das Item i02r bereits umkodiert - genau wie alle Items im Datensatz die mit dem Suffix r gekennzeichnet sind. anderen Situationen kann es aber nötig sein, Items umzukodieren. Vergessen Sie dann nicht, das Ergebnis als (neuen) Datensatz zu speichern.Übrigens macht es rec() noch einfacher und zwar mit dem Parameterwert “rev” (wie revert):","code":"1 --> 4\n2 --> 3\n3 --> 2\n4 --> 1\nextra %>% \n  rec(i02r, rec = \"1=4; 2=3; 3=2; 4=1\")\nextra %>% \n  rec(i02r, rec = \"rev\")"},{"path":"daten-aufräumen.html","id":"extraversionsscore-berechnen","chapter":"Kapitel 2 Daten aufräumen","heading":"2.8 Extraversionsscore berechnen","text":"","code":""},{"path":"daten-aufräumen.html","id":"summen--und-mittelwerte","chapter":"Kapitel 2 Daten aufräumen","heading":"2.8.1 Summen- und Mittelwerte","text":"der Psychometrie werden komplexe Konstrukte wie etwa das Persönlichkeitsmerkmal Extraversion anhand mehrerer Indikatoren (meistens Items eines Fragebogens) gemessen. Um zu einem Personenwert für Extraversion zu gelangen, werden die Itemwerte im einfachsten Fall summiert. Alternativ kann man auch einen Mittelwert bilden. Dieses Aggregieren bietet den Vorteil, dass sich Messfehler (möglicherweise) herausmitteln. Außerdem versucht man abzubilden, dass Extraversion aus mehreren unterschiedlichen Facetten besteht, die nicht mit einem einzelnen Item, sondern über mehrere unterschiedliche Items, erfasst werden. Viele Psychometriker sind skeptisch, wenn man versuchen würde, Extraversion mit der Frage “Wie extrovertiert sind Sie?” zu erfassen. Ihre Bedenken sind, dass Menschen die vielen Facetten von Extraversion nicht im Arbeitsgedächtnis vorhalten können. Fragt man hingegen nur einen kleinen Aspekt von Extraversion ab, trägt man der Breite des Konstrukts nicht Rechnung.Ein einfaches Beispiel zur Berechnung des Extraversion-Summenscore:Der Wert von extra_sum berechnet sich jeweils als Summe der drei Itemwerte. Mit dem Mittelwert verhält es sich analog (s. Tabelle 2.1).Table 2.1: Extraversion-Score berechnenPraktischerweise gibt es Funktionen, die die Berechnung eines Scores noch weiter vereinfachen, zum Beispiel im Paket sjmisc: row_sums() (Summenscore pro Person) und row_means() (Mittelwert pro Person).\nDa Respondenten (meist Personen) Zeilen stehen heißen die Befehle row_XXX().\nFragt sich noch, ob es mehr Sinn macht, einen Summenscore oder einen Mittelwert zu berechnen. Kurz gesagt macht es keinen großen Unterschied, solange es keine fehlenden Werte gibt.\nGibt es aber fehlende Werte, sollte man Mittelwerte statt Summenwerte vorziehen.","code":"\nextra_bsp <- extra %>%\n  select(i01:i03) %>%\n  slice_head(n = 3) %>%\n  mutate(extra_sum = i01 + i02r + i03)\n\nextra_bsp\n#> # A tibble: 3 × 4\n#>     i01  i02r   i03 extra_sum\n#>   <dbl> <dbl> <dbl>     <dbl>\n#> 1     3     3     3         9\n#> 2     2     2     1         5\n#> 3     3     4     1         8\nextra_bsp <- extra_bsp %>%\n  mutate(extra_mean = extra_sum / 3)"},{"path":"daten-aufräumen.html","id":"vertiefung-summen--vs.-mittelwertscores","chapter":"Kapitel 2 Daten aufräumen","heading":"2.8.2 Vertiefung: Summen- vs. Mittelwertscores","text":"Dazu ein erläuterndes Beispiel. Alois habe einem Persönlichkeitstest mit 3 Items nur Item 1 beantwortet und zwar mit “3”, wobei Antwortstufen von 1 bis 4 vorgegeben waren. Vermutlich ist der Gesamtwert im Form des Summenscores von 3 zu klein, unterschätzt als Alois’ Wert. Schließlich hat er beim ersten Item die Antwort “3” gewählt, insofern ist es plausibel, dass er bei den anderen auch diese Option gewählt hätte. Somit hätte er insgesamt 9 Punkte (nicht 3) erzielt. Würden wir 3 als Gesamtwert (Summenscore) annehmen, bedeutet das, das wir davon ausgehen, dass er im Schnitt “1” gewählt hat. Eine Annahme, die nicht sehr plausibel erscheint.Vergleichen wir das mit dem Mittelwert-Score. Jetzt lassen wir R die Rechenarbeit machen:Der Mittelwert von Alois beträgt 3 – das passt genau zu unserer Argumentation von gerade (s. oben), dass 3 eine bessere Schätzung der Ausprägung der latenten Variable von Alois ist. Daher ist der Mittelwert dem Summenscore vorzuziehen.Ein anderer Vorteil des Mittelwerts ist, dass er etwas anschaulicher ist als der Summenscore: Ein Mittelwert von 3 (auf einer Skala von 1 bis 4) ist anschaulicher als eine Summe von 9 (bei drei Items). Wir werden daher den Mittelwert vorziehen.","code":"\nAlois <- c(3, NA, NA)\nmean(Alois, na.rm = TRUE)\n#> [1] 3"},{"path":"daten-aufräumen.html","id":"berechnung-mit-r","chapter":"Kapitel 2 Daten aufräumen","heading":"2.8.3 Berechnung mit R","text":"Der Parameter n bei row_means() gibt den Anteil der nicht fehlenden Werte (pro Zeile) wieder, damit ein Wert berechnet wird: Bei zu vielen fehlenden Werten (zu wenig Daten) pro Person wird sonst NA zurückgeliefert. Das ist sinnvoll, denn hat eine Person von 10 Items nur 1 Item beantwortet, kann man wohl nicht zuverlässig sagen, dass Extraversion seiner Breite zuverlässig geschätzt wird. Die Funktion fügt dem Datensatz eine Spalte hinzu, deren Name mit var angegeben wird.","code":"\nextra %>% \n  row_means(i01:i10, n = .90, var = \"extra_avg\") %>% \n  select(extra_avg) %>% \n  slice_head(n = 3)\n#> # A tibble: 3 × 1\n#>   extra_avg\n#>       <dbl>\n#> 1       2.9\n#> 2       2.1\n#> 3       2.6"},{"path":"daten-aufräumen.html","id":"z-werte","chapter":"Kapitel 2 Daten aufräumen","heading":"2.8.4 z-Werte","text":"Man kann die Aussagekraft eines Mittelwerts noch erhöhen, dem man ihn z-skaliert. Das geht zum Beispiel :Die Funktion std() z-standardisiert eine oder mehrere angegebene Spalten. Dabei werden neue Spalten erzeugt, deren Namen gleich dem alten Namen plus dem Suffix _z entspricht. Betrachten wir die ersten drei Zeilen:Zu beachten ist, dass der Mittelwert der Stichprobe und deren Standardabweichung als Referenzwerte herangezogen wurden, nicht die entsprechenden Größen der Normierungsstichprobe. Dazu später mehr.","code":"\nextra_std <- extra %>% \n  std(extra_mean)\nextra_std %>% \n  select(extra_mean, extra_mean_z) %>% \n  slice_head(n = 3)\n#> # A tibble: 3 × 2\n#>   extra_mean extra_mean_z\n#>        <dbl>        <dbl>\n#> 1        2.9       0.0202\n#> 2        2.1      -1.75  \n#> 3        2.6      -0.644"},{"path":"daten-aufräumen.html","id":"prozentränge","chapter":"Kapitel 2 Daten aufräumen","heading":"2.8.5 Prozentränge","text":"Den Prozentrang einer Person kann man sich z.B. mit percent_rank() ausgeben lassen:Mit der letzten Zeile - filter(...) haben wir uns das extremste Prozent (hälftig unten und oben) ausgewählt.Dabei ist \\(\\sigma^2_{E_X}\\) der quadrierte Standardmessfehler, \\(\\sigma^2_X\\) die Varianz des Messwerts und \\(\\rho_{tt}\\) die Reliabilität des Messwerts. Die Wurzel daraus ist der sog. Standardmessfehler:\\[\\sigma_{E_X} = \\sigma_x \\cdot \\sqrt{(1-\\rho_{tt})}\\]Die Reliabilität hatten wir vorher schon definiert,\nhier zur Erinnerung:Berechnen wir nun mit Hilfe von R den Standardmessfehler:Jetzt, da wir den Standardmessfehler kennen, können wir gewohnter Manier “links und rechts” auf einen Messwert den zweifachen Wert des Standardmessfehlers draufpacken, um ein 95% Konfidenzintervall zu erhalten:","code":"\nextra_std <- extra_std %>% \n  mutate(extra_percrank = percent_rank(extra_mean))\n\nextra_std %>% \n  select(extra_mean, extra_mean_z, extra_percrank) %>% \n  filter(extra_percrank < .005 | extra_percrank > .995)\n#> # A tibble: 11 × 3\n#>    extra_mean extra_mean_z extra_percrank\n#>         <dbl>        <dbl>          <dbl>\n#>  1        4           2.46        1      \n#>  2        1.7        -2.64        0.00487\n#>  3        3.9         2.23        0.999  \n#>  4        1.6        -2.86        0.00122\n#>  5        1.6        -2.86        0.00122\n#>  6        1.7        -2.64        0.00487\n#>  7        1.6        -2.86        0.00122\n#>  8        3.8         2.01        0.995  \n#>  9        1.2        -3.74        0      \n#> 10        3.8         2.01        0.995  \n#> 11        3.8         2.01        0.995\nextra_alpha <- .87\nextra_stdmessfehler = sd(extra$extra_mean, na.rm = TRUE) * sqrt(1 - extra_alpha)\nextra_stdmessfehler\n#> [1] 0.1628459\nextra <- extra %>% \n  mutate(KI_unten = extra_mean - 2*extra_stdmessfehler,\n         KI_oben = extra_mean + 2*extra_stdmessfehler)\n\nextra %>% \n  select(KI_unten, extra_mean, KI_oben) %>% \n  slice_head(n = 3)\n#> # A tibble: 3 × 3\n#>   KI_unten extra_mean KI_oben\n#>      <dbl>      <dbl>   <dbl>\n#> 1     2.57        2.9    3.23\n#> 2     1.77        2.1    2.43\n#> 3     2.27        2.6    2.93"},{"path":"daten-aufräumen.html","id":"visualisierung-der-konfidenzintervalle","chapter":"Kapitel 2 Daten aufräumen","heading":"2.8.6 Visualisierung der Konfidenzintervalle","text":"Eine Visualisierung der Konfidenzintervalle kann ansprechend sein; hier ist eine Möglichkeit dazu:geom_pointrange() zeichnet einen vertikalen (Fehler-)balken sowie einen Punkt der Mitte;\nals Parameter werden der mittlere Wert, die untere Grenze und die obere Grenze angegeben. Nach der Tilde steht die Variable der X-Achse.","code":"\nextra %>% \n  slice_head(n = 5) %>% \n  ggplot() +\n  aes(y = extra_mean, ymin = KI_unten, ymax = KI_oben, x = code) +\n  geom_pointrange()"},{"path":"daten-aufräumen.html","id":"profildiagramme","chapter":"Kapitel 2 Daten aufräumen","heading":"2.8.7 Profildiagramme","text":"Definieren wir uns einen Auszug Personen und Variablen (Items), die einem Diagramm dargestellt sein sollen.Dann überführen wir dieses Diagramm die “lange” Form:Jetzt können wir daraus ein Balkendiagramm darstellen:Dem Skalenniveau der Items kommen Punkte vielleicht besser entgegen als die Balken:","code":"\nextra_auszug <- extra %>% \n  select(code, i01:i06r) %>% \n  slice(1:6) \nextra_auszug <- extra_auszug %>% \n  pivot_longer(-code, names_to = \"Item\", values_to = \"Wert\")\nextra_auszug %>% \n  ggplot(aes(y = Wert, x = Item, fill = code)) +\n  geom_col() +\n  facet_wrap(~ code)\nextra_auszug %>% \n  ggplot(aes(y = Wert, x = Item, color = code)) +\n  geom_line(group = 1) +\n  geom_point() +\n  facet_wrap(~ code)"},{"path":"fallstudie-popup-stores.html","id":"fallstudie-popup-stores","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"Kapitel 3 Fallstudie Popup-Stores","text":"","code":""},{"path":"fallstudie-popup-stores.html","id":"r-pakete-2","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.1 R-Pakete","text":"diesem Kapitel benötigen wir folgende R-Pakete:","code":"\nlibrary(tidyverse)  # Datenjudo\nlibrary(sjmisc)  # Datenhausmeister\nlibrary(janitor)  # Auch ein Hausmeister\nlibrary(easystats)  # Stats made easy :-)\nlibrary(flextable)  # html Tabellen, schick"},{"path":"fallstudie-popup-stores.html","id":"einleitung-1","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.2 Einleitung","text":"einer Studie untersuchte Frau Prof. Dr. Klug Ursachen von Entscheidungen im Rahmen von Einstellungen und Verhalten bei Pop-Stores.U.. wurden folgende Fragen untersucht:Welchen (kausalen) Effekt hat die Distanz zum und Lage des Pop--Stores hinsichtlich der AV?Wie stark ist der Moderatoreffekt von Variablen wie z.B. Innovationsorientierung, Shopping-Relevnaz und Soziodemografika?Ist ein Effekt auf Einstellung, Verhaltensintention und Verhalten zu beobachten?Es handelt sich um ein experimentelles Design mit zwei Faktoren (Lage und Distanz) mit jeweils 3 Stufen.Ein Teil der Daten ist (nur) für Lehrzwecke freigeben.Folgende Materialien stehen bereit:Roh-Datensatz, \\(n=90\\), Gruppen 1-3StudienkonzeptFrageobgenCodebook","code":""},{"path":"fallstudie-popup-stores.html","id":"aufgaben","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.3 Aufgaben","text":"Entfernen Sie leere Zeilen und Spalten aus dem Datensatz. Tipp: Nutzen Sie das R-Paket {{janitor}}.Entfernen Sie konstante Variablen. Tipp: Nutzen Sie das R-Paket {{janitor}}.Prüfen Sie auf Duplikate, d.h. doppelte Zeilen. Tipp: Nutzen Sie das R-Paket {{janitor}}.Entfernen Sie alle Spalten, die Zeit-Objekte enthalten.Ersetzen Sie leere Zellen sowie Zellen mit Inhalt \"N/\" durch NA, also durch einen fehlenden Wert. Tipp: na_if() aus {{dplyr}}.Rekodieren Sie die Anker (Labels) der Ratingskala Zahlen und zwar von -3 bis +3! Tipp: Nutzen Sie recode() aus {{dplyr}}.Berechnen Sie Spalten-Mittelwerte für alle Konstrukte, die die Ratingskala verwenden. Tipp: Nutzen Sie rowwise() und c_across().Exportieren Sie die Daten als CSV- und als XLSX-Datei. Tipp: Nutzen Sie das R-Paket {{rio}}.Berechnen Sie Cronbachs Alpha! Tipp: Nutzen Sie das R-Paket {{psych}}.Berechnen Sie gängige deskriptive Statistiken für die Mittelwerte der Konstrukte. Tipp: Nutzen Sie das R-Paket {{easystats}} und daraus die Funktion describe_distribution().Importieren Sie diese Tabelle nach Word! Tipp: Nutzen Sie das R-Paket {{flextable}}.Kurz vor Abgabe Ihres Studienberichts fällt Ihnen ein, dass Sie vergessen haben, das Item v033 zu invertieren. Das möchten Sie noch schnell nachholen. Tipp: Einfaches Rechnen.","code":""},{"path":"fallstudie-popup-stores.html","id":"lösungen","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4 Lösungen","text":"","code":""},{"path":"fallstudie-popup-stores.html","id":"ad-1","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4.1 Ad 1","text":"Daten laden:Die Tabelel umfasst 90 Zeilen und 196 Spalten.Leere Zeilen/Spalten entfernen:","code":"\nd_url <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/popupstore/data/d1a.csv\"\n\nd1a <- read_csv(d_url)\n\ndim(d1a)\n#> [1]  90 196\nlibrary(janitor)\nd2 <-\n  d1a %>% \n  remove_empty()"},{"path":"fallstudie-popup-stores.html","id":"ad-2","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4.2 Ad 2","text":"","code":"\nlibrary(janitor)\nd3 <-\n  d2 %>% \n  remove_constant()"},{"path":"fallstudie-popup-stores.html","id":"ad-3","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4.3 Ad 3","text":"Keine Duplikate zu finden.","code":"\nd3 %>% \n  get_dupes()\n#> # A tibble: 0 × 84\n#> # … with 84 variables: v001 <dbl>, v002 <dttm>, v003 <dbl>,\n#> #   v005 <dbl>, v006 <dttm>, v007 <dttm>, v008 <chr>,\n#> #   v009 <chr>, v010 <chr>, v011 <chr>, v012 <chr>,\n#> #   v013 <chr>, v014 <chr>, v015 <chr>, v016 <chr>,\n#> #   v017 <chr>, v018 <chr>, v019 <chr>, v020 <chr>,\n#> #   v021 <chr>, v022 <chr>, v023 <dbl>, v033 <chr>,\n#> #   v034 <chr>, v035 <chr>, v036 <chr>, v037 <chr>, …"},{"path":"fallstudie-popup-stores.html","id":"ad-4","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4.4 Ad 4","text":"","code":"\nd4 <-\n  d3 %>% \n  select(-c(v002, v006, v007))"},{"path":"fallstudie-popup-stores.html","id":"ad-5","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4.5 Ad 5","text":".Und weiter für alle Spalten …Puh, geht das nicht schlauer?Ja, geht. Hier ein kleiner Trick:Mit map_df() kann man eine Funktion, hier na_if() auf jede Spalte der Tabelle (hier: d5) anwenden.\nAls Ergebnis dieses “Funktions-Mapping” soll wieder eine Tabelle - daher map_df zurückgegeben werden.Mal ein Check:\nDie Anzahl der fehlenden Werte müsste sich jetzt erhöht haben im Vergleich zur letzten Version des Datensatz, d4:Hm, g.ar nicht viele mehr. Aber grundsätzlich hat es funktioniert :-)Sie brauchen map_df() nicht zu verwenden. Es geht auch ohne. Mit map_df() ist es nur komfortabler.","code":"\nd4 %>% \n  mutate(v001 = na_if(v001, \"\"),\n         v001 = na_if(v001, \"N/A\"))\n#> # A tibble: 90 × 80\n#>     v001  v003      v005 v008  v009  v010  v011  v012  v013 \n#>    <dbl> <dbl>     <dbl> <chr> <chr> <chr> <chr> <chr> <chr>\n#>  1   794    25    1.03e9 2a02… <NA>  Ja    Ja    Nein  Nein \n#>  2   146    25    1.38e9 2a02… <NA>  Ja    Ja    Nein  Nein \n#>  3   459     4    3.55e8 2003… http… Nein  Ja    Nein  Ja   \n#>  4   324    25    9.95e8 134.… http… Ja    Ja    Nein  Nein \n#>  5   257    25    6.89e8 2003… http… Nein  Nein  Nein  Ja   \n#>  6   182    25    1.70e9 2003… http… Nein  Nein  Nein  Nein \n#>  7    95    25    1.70e9 93.1… http… Ja    Nein  Ja    Nein \n#>  8   355    25    1.60e9 2a02… http… Ja    Nein  Nein  Ja   \n#>  9   570    25    8.10e8 2003… http… Nein  Nein  Nein  Nein \n#> 10   173    25    7.67e7 134.… http… Ja    Nein  Nein  Nein \n#> # … with 80 more rows, and 71 more variables: v014 <chr>,\n#> #   v015 <chr>, v016 <chr>, v017 <chr>, v018 <chr>,\n#> #   v019 <chr>, v020 <chr>, v021 <chr>, v022 <chr>,\n#> #   v023 <dbl>, v033 <chr>, v034 <chr>, v035 <chr>,\n#> #   v036 <chr>, v037 <chr>, v038 <chr>, v039 <chr>,\n#> #   v040 <chr>, v041 <chr>, v042 <chr>, v043 <chr>,\n#> #   v044 <chr>, v045 <chr>, v046 <chr>, v047 <chr>, …\nd5 <-\n  d4 %>% \n  map_df(na_if, \"\") %>% \n  map_df(na_if, \"N/A\")\nsum(is.na(d4))\n#> [1] 1806\nsum(is.na(d5))\n#> [1] 1893"},{"path":"fallstudie-popup-stores.html","id":"ad-6","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4.6 Ad 6","text":"Die Item-Positionen, wann also die Items der Ratingskala beginnen und wann (welcher Spaltenposition) sie enden,\nist im Fragebogen ersichtlich.Das hat also funktioniert. Aber das jetzt für alle Spalte zu übernehmen,\npuh, viel zu langweilig.\nGibt’s da vielleicht einen Trick?Ja, gibt es.Mit across() kann man eine Funktion (oder mehrere), .fns, über mehrere Spalten, .cols anwenden,\nhier wenden wir recode() auf alle Spalten der Ratingskala .","code":"\nd5 %>% \n  mutate(v033_r = recode(v033,\n      \"lehne voll und ganz ab\" = -3,\n      \"lehne ab\" = -2,\n      \"lehne eher ab\" = -1,\n      \"weder/noch\" = 0,\n      \"stimme eher zu\" = 1,\n      \"stimme zu\" = 2,\n      \"stimme voll und ganz zu\" = 3,\n      .default = NA_real_  # Ansonsten als NA und zwar NA vom Typ \"reelle Zahl\"\n  )) %>% \n  select(v001, v033, v033_r) %>% \n  head(10)\n#> # A tibble: 10 × 3\n#>     v001 v033                    v033_r\n#>    <dbl> <chr>                    <dbl>\n#>  1   794 stimme voll und ganz zu      3\n#>  2   146 stimme eher zu               1\n#>  3   459 <NA>                        NA\n#>  4   324 stimme eher zu               1\n#>  5   257 lehne eher ab               -1\n#>  6   182 stimme zu                    2\n#>  7    95 stimme eher zu               1\n#>  8   355 stimme zu                    2\n#>  9   570 stimme eher zu               1\n#> 10   173 lehne eher ab               -1\nd6 <-\n  d5 %>%\n  mutate(across(\n    .cols = c(v033:v056, v087:v104),\n    .fns = ~ recode(.,\n      \"lehne voll und ganz ab\" = -3,\n      \"lehne ab\" = -2,\n      \"lehne eher ab\" = -1,\n      \"weder/noch\" = 0,\n      \"stimme eher zu\" = 1,\n      \"stimme zu\" = 2,\n      \"stimme voll und ganz zu\" = 3,\n      .default = NA_real_  # Andere Wete als NA (Fehlende Werte) vom Typ \"reelle Zahl\" kennzeichnen\n    )\n  ))"},{"path":"fallstudie-popup-stores.html","id":"ad-7","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4.7 Ad 7","text":"c_across() ist wie c(). Allerdings funktioniert c() leider nicht für zeilenweise Operationen.\nDaher braucht es einen Freund, der das kann, c_across().","code":"\nd7 <-\n  d6 %>%\n  rowwise() %>%  # Zeilenweise arbeiten im Folgenden\n  mutate(\n    exp_avg = mean(c_across(v033:v039), na.rm = TRUE),\n    neu_avg = mean(c_across(v040:v042), na.rm = TRUE),\n    att_avg = mean(c_across(v043:v047), na.rm = TRUE),\n    ka_avg = mean(c_across(v048:v053), na.rm = TRUE), \n    wom_avg = mean(c_across(v054:v056), na.rm = TRUE),\n    innp_avg = mean(c_across(v087:v092), na.rm = TRUE),\n    imp_avg = mean(c_across(v093:v096), na.rm = TRUE),\n    hedo_avg = mean(c_across(v097:v100), na.rm = TRUE),\n    sho1_avg = mean(c_across(v101:v104), na.rm = TRUE)\n  ) %>%\n  relocate(ends_with(\"_avg\"), .after = v008)  # wir verschieben alle Spalten, die mit `_avg` enden nach vorne"},{"path":"fallstudie-popup-stores.html","id":"ad-8","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4.8 Ad 8","text":"","code":"\nlibrary(rio)\nexport(d7, file = \"d7.csv\")\nexport(d7, file = \"d7.xlsx\")"},{"path":"fallstudie-popup-stores.html","id":"ad-9","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4.9 Ad 9","text":"","code":"\nlibrary(psych)\n\nd7 %>% \n  select(v087:v092) %>% \n  alpha(title = \"Skala Innovationsorientierung\")\n#> \n#> Reliability analysis  Skala Innovationsorientierung  \n#> Call: alpha(x = ., title = \"Skala Innovationsorientierung\")\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N  ase  mean  sd\n#>       0.87      0.88    0.88      0.54   7 0.02 -0.25 1.3\n#>  median_r\n#>      0.52\n#> \n#>  lower alpha upper     95% confidence boundaries\n#> 0.83 0.87 0.91 \n#> \n#>  Reliability if an item is dropped:\n#>      raw_alpha std.alpha G6(smc) average_r S/N alpha se\n#> v087      0.84      0.84    0.83      0.52 5.4    0.026\n#> v088      0.83      0.83    0.83      0.50 5.0    0.028\n#> v089      0.87      0.87    0.87      0.57 6.5    0.022\n#> v090      0.84      0.84    0.84      0.51 5.1    0.028\n#> v091      0.87      0.87    0.87      0.57 6.5    0.023\n#> v092      0.87      0.87    0.87      0.58 6.9    0.022\n#>      var.r med.r\n#> v087 0.013  0.51\n#> v088 0.015  0.51\n#> v089 0.024  0.55\n#> v090 0.022  0.51\n#> v091 0.018  0.51\n#> v092 0.018  0.55\n#> \n#>  Item statistics \n#>       n raw.r std.r r.cor r.drop  mean  sd\n#> v087 61  0.83  0.83  0.82   0.73  0.16 1.8\n#> v088 61  0.87  0.87  0.87   0.80  0.49 1.5\n#> v089 61  0.74  0.73  0.65   0.60 -0.75 1.8\n#> v090 61  0.86  0.86  0.83   0.78 -0.80 1.7\n#> v091 61  0.71  0.73  0.65   0.60  0.00 1.4\n#> v092 61  0.70  0.70  0.62   0.57 -0.59 1.6\n#> \n#> Non missing response frequency for each item\n#>        -3   -2   -1    0    1    2    3 miss\n#> v087 0.07 0.15 0.20 0.08 0.26 0.15 0.10 0.32\n#> v088 0.02 0.11 0.13 0.18 0.31 0.15 0.10 0.32\n#> v089 0.13 0.30 0.21 0.15 0.05 0.10 0.07 0.32\n#> v090 0.21 0.18 0.18 0.20 0.11 0.08 0.03 0.32\n#> v091 0.07 0.10 0.16 0.25 0.30 0.13 0.00 0.32\n#> v092 0.15 0.16 0.18 0.25 0.16 0.10 0.00 0.32"},{"path":"fallstudie-popup-stores.html","id":"ad-10","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4.10 Ad 10","text":"","code":"\nlibrary(easystats)\n\nd7 %>% \n  select(ends_with(\"_avg\")) %>% \n  describe_distribution()\n#> Variable |  Mean |   SD |  IQR |         Range | Skewness |  Kurtosis |  n | n_Missing\n#> --------------------------------------------------------------------------------------\n#> exp_avg  |  0.90 | 1.12 | 1.57 | [-1.86, 3.00] |    -0.45 |     -0.16 | 76 |        14\n#> neu_avg  |  1.22 | 1.25 | 1.33 | [-2.67, 3.00] |    -0.96 |      0.79 | 70 |        20\n#> att_avg  |  1.04 | 1.13 | 1.20 | [-2.60, 3.00] |    -1.16 |      1.93 | 68 |        22\n#> ka_avg   |  0.91 | 1.20 | 1.21 | [-2.17, 3.00] |    -1.07 |      0.54 | 66 |        24\n#> wom_avg  |  0.31 | 1.16 | 1.25 | [-2.33, 3.00] |     0.35 |      0.23 | 64 |        26\n#> innp_avg | -0.25 | 1.28 | 1.50 | [-2.83, 2.67] |     0.07 |     -0.28 | 61 |        29\n#> imp_avg  | -0.28 | 1.18 | 1.50 | [-3.00, 2.50] |    -0.32 | -7.40e-03 | 61 |        29\n#> hedo_avg |  0.34 | 1.40 | 1.50 | [-3.00, 3.00] |    -0.69 |      0.40 | 60 |        30\n#> sho1_avg | -0.80 | 1.51 | 2.75 | [-3.00, 2.25] |     0.28 |     -0.85 | 60 |        30"},{"path":"fallstudie-popup-stores.html","id":"ad-11","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4.11 Ad 11","text":"Es gibt mehrere Wege, das Ziel zu erreichen.\nEiner sieht aus.VariableMeanSDIQRMinMaxSkewnessKurtosisnn_Missingexp_avg0.89661651.1162621.571429-1.8571433.000000-0.44852912-0.1552029287614neu_avg1.22380951.2481501.333333-2.6666673.000000-0.959038220.7902116037020att_avg1.04411761.1339251.200000-2.6000003.000000-1.163480101.9271886886822ka_avg0.90909091.2029811.208333-2.1666673.000000-1.065406800.5397606186624wom_avg0.30729171.1612571.250000-2.3333333.0000000.351188560.2326763076426innp_avg-0.24863391.2767951.500000-2.8333332.6666670.06946976-0.2808001726129imp_avg-0.28278691.1774581.500000-3.0000002.500000-0.32165605-0.0073983446129hedo_avg0.33750001.4012901.500000-3.0000003.000000-0.686592300.3975272586030sho1_avg-0.80416671.5064072.750000-3.0000002.2500000.27889917-0.8475168866030Vielleicht noch die Anzahl der Dezimalstellen beschneiden:VariableMeanSDIQRMinMaxSkewnessKurtosisnn_Missingexp_avg0.901.121.57-1.863.00-0.45-0.167614neu_avg1.221.251.33-2.673.00-0.960.797020att_avg1.041.131.20-2.603.00-1.161.936822ka_avg0.911.201.21-2.173.00-1.070.546624wom_avg0.311.161.25-2.333.000.350.236426innp_avg-0.251.281.50-2.832.670.07-0.286129imp_avg-0.281.181.50-3.002.50-0.32-0.016129hedo_avg0.341.401.50-3.003.00-0.690.406030sho1_avg-0.801.512.75-3.002.250.28-0.856030Und speichert man als Word-Datei:","code":"\nlibrary(flextable)\n\nflex1 <- \n  d7 %>% \n  select(ends_with(\"_avg\")) %>% \n  describe_distribution() %>% \n  flextable()\n\nflex1\nflex1 <- \n  d7 %>% \n  select(ends_with(\"_avg\")) %>% \n  describe_distribution() %>% \n  adorn_rounding(digits = 2) %>% \n  flextable()\n\nflex1\nsave_as_docx(flex1, path = \"flex1.docx\")"},{"path":"fallstudie-popup-stores.html","id":"ad-12","chapter":"Kapitel 3 Fallstudie Popup-Stores","heading":"3.4.12 Ad 12","text":"Wie kann ich Items konvertieren? Also negativ gepolte Items positiv umkodieren, also “umdrehen”?Die Skala erstreckt sich von -3 bis +3.\nMit recode() kann man wie oben auch entsprechend umkodieren.Die Backticks brauchen wir,\nweil es sich bei -1 etc. nicht um syntaktisch korrekte Variablennamen handelt.Tipp: Einfach mal die Hilfe schauen.","code":"\nd8 <-\n  d7 %>% \n  mutate(v033_i = dplyr::recode(v033,\n                         `-3` = +3,\n                         `-2` = +2,\n                         `-1` = 1,\n                         `0` = 0,\n                         `1` = -1,\n                         `2` = -2,\n                         `3` = -3))\ni <- 1\n`i ist eins` <- 1\ni1 <- 1"},{"path":"normierung.html","id":"normierung","chapter":"Kapitel 4 Normierung","heading":"Kapitel 4 Normierung","text":"","code":""},{"path":"normierung.html","id":"r-pakete-3","chapter":"Kapitel 4 Normierung","heading":"4.1 R-Pakete","text":"diesem Kapitel benötigen wir folgende R-Pakete:","code":"\nlibrary(tidyverse)  # Datenjudo\nlibrary(sjmisc)  # Datenhausmeister\nlibrary(mice)  # fehlende Daten imputieren"},{"path":"normierung.html","id":"daten-2","chapter":"Kapitel 4 Normierung","heading":"4.1.1 Daten","text":"","code":"\ndata_url <- \"https://raw.githubusercontent.com/sebastiansauer/modar/master/datasets/extra.csv\"\nextra <- read_csv(data_url)"},{"path":"normierung.html","id":"vergleich-mit-normierungsstichprobe","chapter":"Kapitel 4 Normierung","heading":"4.2 Vergleich mit Normierungsstichprobe","text":"Satow (2012) berichtet Normierungswerte, leider aber nur für die Allgemeinbevölkerung,\nnicht heruntergebrochen auf Geschlechter- oder Altersgruppen. Für Extraversion berichtet er folgende Daten:Summenscore: 26,67Standardabweichung: 5,74Auf Errisch:Ob die Daten normal verteilt sind, wird der Publikation nicht erwähnt.\nWir gehen im Folgenden davon aus. Allerdings ist es ein Manko, wenn diese Information nicht gegeben ist.\nWeiter berichtet Satow (2012) nicht, ob fehlende Werte die Summenscores verringert haben bzw. wie er ggf. mit diesem Problem umgegangen ist.\nBevor wir den Vergleich mit der Normierungsstichprobe heranziehen können, müssen wir uns um fehlende Werte kümmern.","code":"\nextra_sum_normstipro <- 26.67\nextra_sd_normstipro <- 5.74"},{"path":"normierung.html","id":"anzahl-der-fehlenden-werte","chapter":"Kapitel 4 Normierung","heading":"4.2.1 Anzahl der fehlenden Werte","text":"Eine Möglichkeit, fehlende Werte zu zählen, sieht aus:Wir haben Glück; es gibt keine fehlenden Werte diesem Datensatz.\nAber haben wir wirklich Glück? Vermutlich wurden die Respondenten gezwungen, alle Fragen zu beantworten.\nVielleicht wurden sie damit ordentlich genervt und haben zur Strafe Blümchen gekreuzt?\nWir wissen es nicht genau, sollten aber die Datenqualität noch einmal überprüfen.","code":"\nextra %>% \n  row_count(i01:i10, count = \"na\") %>% \n  count(rowcount)\n#> # A tibble: 1 × 2\n#>   rowcount     n\n#>      <int> <int>\n#> 1        0   826"},{"path":"normierung.html","id":"vertiefung-fehlende-werte-ersetzen","chapter":"Kapitel 4 Normierung","heading":"4.2.2 Vertiefung: Fehlende Werte ersetzen","text":"Das Ersetzen fehlender Werte ist eine Wissenschaft für sich, aber ein einfacher (alldieweil nicht optimaler) Weg besteht darin,\ndie fehlenden Werte durch den Mittelwert des Items zu ersetzen.\nEin Item wurde im Schnitt mit 3,2 beantwortet, aber für Alois fehlt der Wert?\nOkay, ersetzen wir den fehlenden Wert für dieses Items mit 3,2.Für i1 ist “1” eine plausible Schätzung für den fehlenden Wert, bei i2 ist “3” sinnvoll und bei i3 “4”, also jeweils der Zeilenmittelwert.Wie wir sehen, wurde jeder Spalte jeder fehlende Wert durch den Spalten-Mittelwert ersetzt.","code":"\ndaten <- data_frame(\n  namen = c(\"Alois\", \"Bertram\", \"Zenzi\"),\n  i1 = c(1, 1, NA),\n  i2 = c(3, 2, NA),\n  i3 = c(NA, 2, 4)\n)\n\ndaten\n#> # A tibble: 3 × 4\n#>   namen      i1    i2    i3\n#>   <chr>   <dbl> <dbl> <dbl>\n#> 1 Alois       1     3    NA\n#> 2 Bertram     1     2     2\n#> 3 Zenzi      NA    NA     4\ndaten_imp <- \n  daten %>% \n  mice(method = \"mean\")\n#> \n#>  iter imp variable\n#>   1   1  i2  i3\n#>   1   2  i2  i3\n#>   1   3  i2  i3\n#>   1   4  i2  i3\n#>   1   5  i2  i3\n#>   2   1  i2  i3\n#>   2   2  i2  i3\n#>   2   3  i2  i3\n#>   2   4  i2  i3\n#>   2   5  i2  i3\n#>   3   1  i2  i3\n#>   3   2  i2  i3\n#>   3   3  i2  i3\n#>   3   4  i2  i3\n#>   3   5  i2  i3\n#>   4   1  i2  i3\n#>   4   2  i2  i3\n#>   4   3  i2  i3\n#>   4   4  i2  i3\n#>   4   5  i2  i3\n#>   5   1  i2  i3\n#>   5   2  i2  i3\n#>   5   3  i2  i3\n#>   5   4  i2  i3\n#>   5   5  i2  i3\n\ndaten2 <- complete(daten_imp, 1)"},{"path":"normierung.html","id":"z-werte-auf-basis-der-normierungsstichprobe","chapter":"Kapitel 4 Normierung","heading":"4.2.3 z-Werte auf Basis der Normierungsstichprobe","text":"Im Handbuch sind, wie oben beschrieben, nur Mittelwert und Streuung des Summenwerts, nicht des Mittelwerts angegeben, also müssen wir mit diesen Werten arbeiten:Zuerst berechnen wir von Hand den z-Score auf Basis der Normierungsstichprobe:","code":"\nextra <- extra %>% \n  row_sums(i01:i10, n = .9, var = \"extra_sum\")\nextra <- extra %>% \n  mutate(extra_z_normstipro = (extra_sum - extra_sum_normstipro) / extra_sd_normstipro) %>% \n  mutate(extra_percrank_normstipro = pnorm(extra_z_normstipro)) \n\nextra %>% \n  select(extra_z_normstipro, extra_percrank_normstipro) %>% \n  slice_head(n = 5)\n#> # A tibble: 5 × 2\n#>   extra_z_normstipro extra_percrank_normstipro\n#>                <dbl>                     <dbl>\n#> 1              0.406                     0.658\n#> 2             -0.988                     0.162\n#> 3             -0.117                     0.454\n#> 4              0.406                     0.658\n#> 5              0.929                     0.823"},{"path":"normierung.html","id":"konfidenzintervalle-für-den-personenparameter","chapter":"Kapitel 4 Normierung","heading":"4.2.4 Konfidenzintervalle für den Personenparameter","text":"Sicherlich ist unsere Messung der Extraversion nicht perfekt; wir müssen davon ausgehen, dass ein Messfehler vorliegt. Eine Berechnungsvorschrift für den Messfehler sieht aus (Bühner 2011):\\[\\sigma^2_{E_X} = \\sigma^2_X \\cdot(1-\\rho_{tt})\\]","code":""},{"path":"diagnostische-kennwerte.html","id":"diagnostische-kennwerte","chapter":"Kapitel 5 Diagnostische Kennwerte","heading":"Kapitel 5 Diagnostische Kennwerte","text":"","code":""},{"path":"diagnostische-kennwerte.html","id":"r-pakete-4","chapter":"Kapitel 5 Diagnostische Kennwerte","heading":"5.1 R-Pakete","text":"diesem Kapitel benötigen wir folgende R-Pakete:","code":"\nlibrary(tidyverse)  # Datenjudo\nlibrary(psych)  # Itemanalyse"},{"path":"diagnostische-kennwerte.html","id":"daten-3","chapter":"Kapitel 5 Diagnostische Kennwerte","heading":"5.2 Daten","text":"","code":"\ndata_url <- \"https://raw.githubusercontent.com/sebastiansauer/modar/master/datasets/extra.csv\"\nextra <- read_csv(data_url)\n#> Rows: 826 Columns: 34\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (8): timestamp, code, sex, presentation, clients, e...\n#> dbl (25): i01, i02r, i03, i04, i05, i06r, i07, i08, i09,...\n#> lgl  (1): i21\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"diagnostische-kennwerte.html","id":"vergleich-vieler-personen-interindividual-differenzierende-diagnostik","chapter":"Kapitel 5 Diagnostische Kennwerte","heading":"5.3 Vergleich vieler Personen (interindividual differenzierende Diagnostik)","text":"","code":""},{"path":"diagnostische-kennwerte.html","id":"histogramm","chapter":"Kapitel 5 Diagnostische Kennwerte","heading":"5.3.1 Histogramm","text":"Eine grundlegende Visualisierung für eine Verteilung - wie z.B. die Testergebnisse einer Stichprobe Bewerbern - ist ein Histogramm:Möchte man mehrere Gruppen vergleichen, ist der Boxplot eine geeignete Visualisierung:","code":"\nextra %>% \n  ggplot(aes(x = extra_mean)) +\n  geom_histogram()\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\n#> Warning: Removed 4 rows containing non-finite values\n#> (stat_bin).\nextra %>% \n  ggplot(aes(y = extra_mean, x = sex)) +\n  geom_boxplot()\n#> Warning: Removed 4 rows containing non-finite values\n#> (stat_boxplot)."},{"path":"diagnostische-kennwerte.html","id":"einzelfalldiagnostik","chapter":"Kapitel 5 Diagnostische Kennwerte","heading":"5.4 Einzelfalldiagnostik","text":"Bisher haben wir einen Wert pro Person ausgerechnet;\neinigen Fällen wird man daran interessiert sein, mehrere Werte einer Person (bzw. einer Beobachtungseinheit) zu berechnen, um ein Profil zu erstellen.\nGehen wir im Folgenden davon aus, dass die einzelnen 10 Items der Extraversionsskala hinreichend belastbare Messwerte sind,\ndie sich lohnen, einzeln darzustellen.\nDer Übersichtlichkeit halber begrenzen wir uns auf die Darstellung von sehr wenig Personen.","code":""},{"path":"diagnostische-kennwerte.html","id":"spinnendiagramm","chapter":"Kapitel 5 Diagnostische Kennwerte","heading":"5.4.1 Spinnendiagramm","text":"Ein Spinnennetz- oder Radardiagramm ist eine Möglichkeit,\nein Werteprofil einer oder mehrerer Personen gleichzeitig darzustellen.\nEs weißt allerdings gravierende Mängel auf (siehehier),\ndass insgesamt von diesem Diagramm abgeraten werden muss.","code":"\nlibrary(radarchart)\n\nlabs <- c(\"Communicator\", \"Data Wangler\", \"Programmer\",\n          \"Technologist\",  \"Modeller\", \"Visualizer\")\n\nitems <- c(\"i01\", \"i02r\", \"i03\", \"i04\", \"i05\", \"i06\")\n\nscores <- list(\n  \"Anna\" = c(9, 7, 4, 5, 3, 7),\n  \"Bert\" = c(7, 6, 6, 2, 6, 9),\n  \"Carl\" = c(6, 5, 8, 4, 7, 6)\n)\n\nchartJSRadar(scores = scores, labs = items, maxScale = 10)"},{"path":"itemanalyse.html","id":"itemanalyse","chapter":"Kapitel 6 Itemanalyse","heading":"Kapitel 6 Itemanalyse","text":"","code":""},{"path":"itemanalyse.html","id":"r-pakete-5","chapter":"Kapitel 6 Itemanalyse","heading":"6.1 R-Pakete","text":"diesem Kapitel benötigen wir folgende R-Pakete:","code":"\nlibrary(tidyverse)  # Datenjudo\nlibrary(sjmisc)  # recode\nlibrary(psych)  # Itemanalyse"},{"path":"itemanalyse.html","id":"daten-4","chapter":"Kapitel 6 Itemanalyse","heading":"6.2 Daten","text":"","code":"\ndata_url <- \"https://raw.githubusercontent.com/sebastiansauer/modar/master/datasets/extra.csv\"\nextra <- read_csv(data_url)\n#> Rows: 826 Columns: 34\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (8): timestamp, code, sex, presentation, clients, e...\n#> dbl (25): i01, i02r, i03, i04, i05, i06r, i07, i08, i09,...\n#> lgl  (1): i21\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"itemanalyse.html","id":"einführung","chapter":"Kapitel 6 Itemanalyse","heading":"6.3 Einführung","text":"Unter Itemanalyse versteht man einen wesentlichen Teil der Validierung eines psychometrischen Tests. Zentrales Element ist die empirische Prüfung der Güte der Items eines Instruments. Entsprechend kann man von der internen Validität eines Tests7 sprechen. Üblicherweise werden dabei die folgenden Aspekte untersucht:ItemschwierigkeitItemtrennschärfeReliabilität (Interne Konsistenz; z.B. mittels Cronbachs Alpha)FaktorenstrukturDie Analyse der Faktorenstruktur ist dieser Analyse nicht umgesetzt.Die ersten drei Punkte werden durch eine Funktion, alpha() aus dem Paket psych abgedeckt. Dieser Funktion übergibt man eine Tabelle mit Items; man bekommt einige Item-Statistiken zurück. Zuerst erstellen wir eine Tabelle, extra_items nur mit den Items.Dann führen wir alpha() mit dieser Tabelle aus:Hilfe zur recht ausführlichen Ausgabe bekommt man ?alpha.Das raw_alpha ist das für gewöhnliche berichtete Alpha-Koeffizient (\\(\\alpha\\)) berechnet auf Basis der Kovarianzen, nicht Korrelationen), als Schätzwert für die Reliabilität im Sinne der internen Konsistenz der Skala. Außerdem wird ein Konfidenzbereich für den Alpha-Koeffizienten angegeben. Interessant ist auch die Frage, ob bzw. wie sich die Reliabilität der Skala ändert, wenn man ein bestimmtes Items entfernt: Wird die Reliabilität besser nach Entfernen des Items, ist das ein Hinweis, dass das Item umformuliert oder entfernt werden sollte. Im vorliegenden Fall ist das Item i03 ein Kandidat zur Überarbeitung.Darüber hinaus wird Guttmans \\(\\lambda_6\\) (Lambda-6) berichtet, der dieser Analyse aber nicht weiter betrachtet wird. average_r ist die mittlere Korrelation aller Itempaare (“Interitemkorrelation”); dieser Koeffizient misst, wie stark die paarweise Korrelation der Items untereinander ist. Bei der Schwierigkeit ist es wünschenswert, dass ein breiter Bereich abgedeckt wird, also einige Items leicht und andere schwer sind, damit Personen mit geringer und hoher Ausprägung der latenten Fähigkeit8 jeweils Items mit passender Schwierigkeit auffinden.mean gibt den Mittelwert der Skala (über alle Items); das ist ein Hinweis zur “Gesamtschwierigkeit” der Skala.Weiter unten der Ausgabe wird für jedes einzelne Item die Schwierigkeit ausgegeben; sd ist die zugehörige Streuung. S/N steht für Signal-Noise-Ratio; dieser Koeffizient wird hier nicht weiter analysiert.Die Itemtrennschärfe (synonym: Part-Whole-Korrelation) wird pro Item mit raw.r angezeigt.","code":"\nextra_items <- extra %>% \n  select(i01:i10) %>% \n  drop_na()\npsych::alpha(extra_items)\n#> \n#> Reliability analysis   \n#> Call: psych::alpha(x = extra_items)\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd\n#>       0.77      0.79     0.8      0.27 3.7 0.012  2.9 0.45\n#>  median_r\n#>      0.27\n#> \n#>  lower alpha upper     95% confidence boundaries\n#> 0.75 0.77 0.8 \n#> \n#>  Reliability if an item is dropped:\n#>      raw_alpha std.alpha G6(smc) average_r S/N alpha se\n#> i01       0.74      0.75    0.76      0.25 3.0    0.014\n#> i02r      0.75      0.76    0.77      0.26 3.2    0.013\n#> i03       0.80      0.80    0.81      0.31 4.1    0.011\n#> i04       0.74      0.75    0.76      0.25 3.0    0.014\n#> i05       0.73      0.75    0.75      0.25 3.0    0.014\n#> i06r      0.75      0.76    0.77      0.26 3.2    0.013\n#> i07       0.75      0.76    0.78      0.27 3.3    0.013\n#> i08       0.76      0.77    0.78      0.27 3.3    0.013\n#> i09       0.76      0.77    0.79      0.28 3.4    0.013\n#> i10       0.77      0.78    0.79      0.29 3.6    0.012\n#>      var.r med.r\n#> i01  0.019  0.25\n#> i02r 0.019  0.27\n#> i03  0.015  0.30\n#> i04  0.017  0.27\n#> i05  0.017  0.24\n#> i06r 0.021  0.28\n#> i07  0.022  0.27\n#> i08  0.023  0.28\n#> i09  0.022  0.29\n#> i10  0.020  0.29\n#> \n#>  Item statistics \n#>        n raw.r std.r r.cor r.drop mean   sd\n#> i01  802  0.69  0.70  0.67   0.59  3.4 0.68\n#> i02r 802  0.63  0.63  0.59   0.50  3.1 0.80\n#> i03  802  0.34  0.32  0.17   0.15  1.8 0.90\n#> i04  802  0.68  0.69  0.68   0.57  3.2 0.73\n#> i05  802  0.71  0.71  0.70   0.60  3.1 0.77\n#> i06r 802  0.60  0.61  0.55   0.48  2.9 0.76\n#> i07  802  0.60  0.60  0.54   0.48  2.9 0.73\n#> i08  802  0.58  0.57  0.49   0.43  2.9 0.87\n#> i09  802  0.52  0.54  0.45   0.40  3.4 0.70\n#> i10  802  0.49  0.47  0.38   0.32  2.2 0.88\n#> \n#> Non missing response frequency for each item\n#>         1    2    3    4 miss\n#> i01  0.01 0.08 0.45 0.45    0\n#> i02r 0.03 0.18 0.45 0.35    0\n#> i03  0.45 0.32 0.18 0.05    0\n#> i04  0.01 0.15 0.44 0.41    0\n#> i05  0.02 0.21 0.47 0.30    0\n#> i06r 0.04 0.20 0.54 0.21    0\n#> i07  0.02 0.22 0.54 0.22    0\n#> i08  0.06 0.23 0.43 0.28    0\n#> i09  0.01 0.09 0.41 0.48    0\n#> i10  0.23 0.43 0.26 0.08    0"},{"path":"itemanalyse.html","id":"literaturempfehlungen","chapter":"Kapitel 6 Itemanalyse","heading":"6.4 Literaturempfehlungen","text":"Bühner (2011) bietet eine gute Einführung die Analyse psychometrischer Daten, allerdings mit SPSS-Syntax, keine R-Syntax.","code":""}]
